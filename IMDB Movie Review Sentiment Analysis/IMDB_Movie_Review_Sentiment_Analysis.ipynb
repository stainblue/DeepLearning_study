{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc764d17",
   "metadata": {},
   "source": [
    "# IMDB 리뷰 감성 분류하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11509cd",
   "metadata": {},
   "source": [
    "## 1. IMDB 리뷰 데이터에 대한 이해"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d3f0acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6873a1c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련용 리뷰 개수 : 25000\n",
      "테스트용 리뷰 개수 : 25000\n",
      "카테고리 : 2\n"
     ]
    }
   ],
   "source": [
    "# 영화 리뷰는 X_train에, 감성 정보는 y_train에 저장된다.\n",
    "# 테스트용 리뷰는 X_test에, 테스트용 리뷰의 감성 정보는 y_test에 저장된다.\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data()\n",
    "\n",
    "# imdb.data_load()의 파라미터로 num_words를 사용하면 \n",
    "# 이 데이터에서 등장 빈도 순위로 몇 번째에 해당하는 단어까지를 사용할 것인지를 의미한다.\n",
    "# (X_train, y_train), (X_test, y_test) = imdb.load_data(num_words = 10000)\n",
    "\n",
    "print('훈련용 리뷰 개수 : {}'.format(len(X_train)))\n",
    "print('테스트용 리뷰 개수 : {}'.format(len(X_test)))\n",
    "num_classes = max(y_train) + 1\n",
    "print('카테고리 : {}'.format(num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "427ca367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 31050, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# 훈련 데이터가 어떻게 구성되어있는지 확인해보기 위해 첫번째 훈련용 리뷰 출력\n",
    "print(X_train[0])\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d6f3a8",
   "metadata": {},
   "source": [
    "리뷰 본문에 해당하는 X_train[0]에는 숫자들이 들어있다. 이 데이터는 **토큰화와 정수 인코딩이라는 텍스트 전처리**가 끝난 상태이다.   \n",
    "IMDB 리뷰 데이터는 전체 데이터에서 각 단어들의 등장 빈도에 따라 인덱스를 부여했다. 숫자가 낮을수록 이 데이터에서 등장 빈도 순위가 높다.   \n",
    "\n",
    "</br>\n",
    "y_train[0]의 값은 1이다. 이 예제의 경우 감성 값으로서 0 또는 1의 값을 가지는데, 이 경우에는 긍정을 의미하는 1의 값을 갖는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24d862e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "리뷰의 최대 길이 : 2494\n",
      "리뷰의 평균 길이 : 238.71364\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 25000개의 훈련용 리뷰의 길이 분포를 그래프로 시각화해보기\n",
    "len_result = [len(s) for s in X_train]\n",
    "\n",
    "print('리뷰의 최대 길이 : {}'.format(np.max(len_result)))\n",
    "print('리뷰의 평균 길이 : {}'.format(np.mean(len_result)))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.boxplot(len_result)\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(len_result, bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69d3ef24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각 레이블에 대한 빈도수:\n",
      "[[    0     1]\n",
      " [12500 12500]]\n"
     ]
    }
   ],
   "source": [
    "# 레이블의 분호 확인하기\n",
    "unique_elements, counts_elements = np.unique(y_train, return_counts=True)\n",
    "print(\"각 레이블에 대한 빈도수:\")\n",
    "print(np.asarray((unique_elements, counts_elements)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93db214e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "빈도수 상위 1등 단어 : the\n",
      "빈도수 상위 1000등 단어 : co\n"
     ]
    }
   ],
   "source": [
    "# X_train에 들어있는 숫자들이 각각 어떤 단어들을 나타내고 있는지 확인\n",
    "# 주의할 점 : IMDB 리뷰 데이터셋에서는 0, 1, 2, 3은 특별한 토큰으로 취급하고 있다.\n",
    "# 따라서 imdb.get_word_index()에 저장된 값에 +3을 해야 실제 맵핑되는 정수이다.\n",
    "word_to_index = imdb.get_word_index()\n",
    "index_to_word={}\n",
    "for key, value in word_to_index.items():\n",
    "    index_to_word[value + 3] = key\n",
    "\n",
    "print('빈도수 상위 1등 단어 : {}'.format(index_to_word[4]))\n",
    "print('빈도수 상위 1000등 단어 : {}'.format(index_to_word[1001]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c88b4d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos> this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert redford's is an amazing actor and now the same being director norman's father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for retail and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also congratulations to the two little boy's that played the part's of norman and paul they were just brilliant children are often left out of the praising list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n"
     ]
    }
   ],
   "source": [
    "# 첫번째 훈련용 리뷰의 X_train[0]이 원래 어떤 단어들이였는지 확인\n",
    "for index, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")):\n",
    "  index_to_word[index]=token\n",
    "\n",
    "print(' '.join([index_to_word[index] for index in X_train[0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570d052e",
   "metadata": {},
   "source": [
    "## 2. GRU로 IMDB 리뷰 감성 분류하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ea5cb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GRU, Embedding\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fc22a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "C:\\Users\\pc\\.conda\\envs\\sentiment_analysis\\lib\\site-packages\\tensorflow\\python\\keras\\datasets\\imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "C:\\Users\\pc\\.conda\\envs\\sentiment_analysis\\lib\\site-packages\\tensorflow\\python\\keras\\datasets\\imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "# 이번엔 집합의 크기를 10,000으로 제한\n",
    "vocab_size = 10000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words = vocab_size)\n",
    "\n",
    "# 각 리뷰는 문장의 길이가 다르기 때문에, 모델이 처리할 수 있도록 길이를 동일하게 해주어야 한다.\n",
    "# pad_sequences()를 사용하면 max_len에 넣는 값으로 길이가 고정된다.\n",
    "# 길이가 초과하면 초과분을 삭제하고, 부족하면 0으로 채운다.\n",
    "max_len = 500\n",
    "X_train = pad_sequences(X_train, maxlen=max_len)\n",
    "X_test = pad_sequences(X_test, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37c416de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.4951 - acc: 0.7658\n",
      "Epoch 00001: val_acc improved from -inf to 0.85900, saving model to GRU_model.h5\n",
      "334/334 [==============================] - 159s 476ms/step - loss: 0.4951 - acc: 0.7658 - val_loss: 0.3261 - val_acc: 0.8590\n",
      "Epoch 2/15\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.3238 - acc: 0.8721\n",
      "Epoch 00002: val_acc improved from 0.85900 to 0.88440, saving model to GRU_model.h5\n",
      "334/334 [==============================] - 163s 488ms/step - loss: 0.3238 - acc: 0.8721 - val_loss: 0.2935 - val_acc: 0.8844\n",
      "Epoch 3/15\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.2658 - acc: 0.9016\n",
      "Epoch 00003: val_acc did not improve from 0.88440\n",
      "334/334 [==============================] - 189s 565ms/step - loss: 0.2658 - acc: 0.9016 - val_loss: 0.3794 - val_acc: 0.8462\n",
      "Epoch 4/15\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.2025 - acc: 0.9255\n",
      "Epoch 00004: val_acc improved from 0.88440 to 0.88540, saving model to GRU_model.h5\n",
      "334/334 [==============================] - 192s 576ms/step - loss: 0.2025 - acc: 0.9255 - val_loss: 0.2847 - val_acc: 0.8854\n",
      "Epoch 5/15\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.1640 - acc: 0.9408\n",
      "Epoch 00005: val_acc improved from 0.88540 to 0.89580, saving model to GRU_model.h5\n",
      "334/334 [==============================] - 192s 576ms/step - loss: 0.1640 - acc: 0.9408 - val_loss: 0.3140 - val_acc: 0.8958\n",
      "Epoch 6/15\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.1288 - acc: 0.9547\n",
      "Epoch 00006: val_acc did not improve from 0.89580\n",
      "334/334 [==============================] - 191s 571ms/step - loss: 0.1288 - acc: 0.9547 - val_loss: 0.3203 - val_acc: 0.8770\n",
      "Epoch 7/15\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.1024 - acc: 0.9649\n",
      "Epoch 00007: val_acc did not improve from 0.89580\n",
      "334/334 [==============================] - 202s 605ms/step - loss: 0.1024 - acc: 0.9649 - val_loss: 0.2786 - val_acc: 0.8928\n",
      "Epoch 8/15\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.0782 - acc: 0.9743\n",
      "Epoch 00008: val_acc did not improve from 0.89580\n",
      "334/334 [==============================] - 195s 583ms/step - loss: 0.0782 - acc: 0.9743 - val_loss: 0.5009 - val_acc: 0.8700\n",
      "Epoch 9/15\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.0575 - acc: 0.9809\n",
      "Epoch 00009: val_acc did not improve from 0.89580\n",
      "334/334 [==============================] - 194s 582ms/step - loss: 0.0575 - acc: 0.9809 - val_loss: 0.4408 - val_acc: 0.8778\n",
      "Epoch 10/15\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.0423 - acc: 0.9860\n",
      "Epoch 00010: val_acc did not improve from 0.89580\n",
      "334/334 [==============================] - 195s 584ms/step - loss: 0.0423 - acc: 0.9860 - val_loss: 0.4440 - val_acc: 0.8766\n",
      "Epoch 11/15\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.0313 - acc: 0.9897\n",
      "Epoch 00011: val_acc did not improve from 0.89580\n",
      "334/334 [==============================] - 221s 661ms/step - loss: 0.0313 - acc: 0.9897 - val_loss: 0.4744 - val_acc: 0.8786\n",
      "Epoch 00011: early stopping\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# Embedding(단어 집합의 크기, 임베딩 후의 벡터 크기)\n",
    "model.add(Embedding(vocab_size, 100))\n",
    "model.add(GRU(128))\n",
    "# 이진 분류이므로 출력층은 뉴런 하나와 활성화 함수로 시그모이드 함수 사용\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# 검증 데이터의 loss가 증가하면, 과적합의 징후이므로\n",
    "# 검증 데이터 loss이 4회 증가하면 학습을 중단하는 EarlyStopping 사용\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
    "\n",
    "# 검증 데이터의 정확도가 이전보다 좋아질 경우에만 모델을 저장하도록 ModelCheckpoint 사용\n",
    "mc = ModelCheckpoint('GRU_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "# 긍정인지 부정인지에 대한 잊니 판별값이 출력이 되기 때문에, 손실함수는 binary_crossentropy 사용\n",
    "# 최적화 함수는 rmsprop 사용\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = model.fit(X_train, y_train, epochs=15, callbacks=[es, mc], batch_size=60, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae9aca74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 74s 94ms/step - loss: 0.3302 - acc: 0.8877\n",
      "\n",
      " 테스트 정확도: 0.8877\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터에 대해서 정확도를 평가\n",
    "# 훈련 과정에서 검증 데이터의 정확도가 가장 높았을 때 저장된 모델인 'GRU_model.h5' 로드\n",
    "loaded_model = load_model('GRU_model.h5')\n",
    "print(\"\\n 테스트 정확도: %.4f\" % (loaded_model.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed37737c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임의의 문장에 대해서 리뷰의 긍정, 부정 예측하는 함수\n",
    "def sentiment_predict(new_sentence):\n",
    "  # 알파벳과 숫자를 제외하고 모두 제거 및 알파벳 소문자화\n",
    "  new_sentence = re.sub('[^0-9a-zA-Z ]', '', new_sentence).lower()\n",
    "\n",
    "  # 정수 인코딩\n",
    "  encoded = []\n",
    "  for word in new_sentence.split():\n",
    "    # 단어 집합의 크기를 10,000으로 제한.\n",
    "    try :\n",
    "      if word_to_index[word] <= 10000:\n",
    "        encoded.append(word_to_index[word]+3)\n",
    "      else:\n",
    "    # 10,000 이상의 숫자는 <unk> 토큰으로 취급.\n",
    "        encoded.append(2)\n",
    "    # 단어 집합에 없는 단어는 <unk> 토큰으로 취급.\n",
    "    except KeyError:\n",
    "      encoded.append(2)\n",
    "\n",
    "  pad_new = pad_sequences([encoded], maxlen = max_len) # 패딩\n",
    "  score = float(loaded_model.predict(pad_new)) # 예측\n",
    "  if(score > 0.5):\n",
    "    print(\"{:.2f}% 확률로 긍정 리뷰입니다.\".format(score * 100))\n",
    "  else:\n",
    "    print(\"{:.2f}% 확률로 부정 리뷰입니다.\".format((1 - score) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98aacfdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.91% 확률로 부정 리뷰입니다.\n"
     ]
    }
   ],
   "source": [
    "temp_str = \"This movie was just way too overrated. The fighting was not professional and in slow motion. I was expecting more from a 200 million budget movie. The little sister of T.Challa was just trying too hard to be funny. The story was really dumb as well. Don't watch this movie if you are going because others say its great unless you are a Black Panther fan or Marvels fan.\"\n",
    "\n",
    "sentiment_predict(temp_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6374aae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.46% 확률로 긍정 리뷰입니다.\n"
     ]
    }
   ],
   "source": [
    "temp_str = \" I was lucky enough to be included in the group to see the advanced screening in Melbourne on the 15th of April, 2012. And, firstly, I need to say a big thank-you to Disney and Marvel Studios. \\\n",
    "Now, the film... how can I even begin to explain how I feel about this film? It is, as the title of this review says a 'comic book triumph'. I went into the film with very, very high expectations and I was not disappointed. \\\n",
    "Seeing Joss Whedon's direction and envisioning of the film come to life on the big screen is perfect. The script is amazingly detailed and laced with sharp wit a humor. The special effects are literally mind-blowing and the action scenes are both hard-hitting and beautifully choreographed.\"\n",
    "\n",
    "sentiment_predict(temp_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "253d5552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88.64% 확률로 부정 리뷰입니다.\n"
     ]
    }
   ],
   "source": [
    "temp_str = \"so bad\"\n",
    "\n",
    "sentiment_predict(temp_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ce5adb0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89.20% 확률로 긍정 리뷰입니다.\n"
     ]
    }
   ],
   "source": [
    "temp_str = \"so good\"\n",
    "\n",
    "sentiment_predict(temp_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e35e137d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67.02% 확률로 긍정 리뷰입니다.\n"
     ]
    }
   ],
   "source": [
    "temp_str = \"There are a lot of c young people who are agitated and watch a drama divided into good and evil.\"\n",
    "\n",
    "sentiment_predict(temp_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4d713f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57.41% 확률로 긍정 리뷰입니다.\n"
     ]
    }
   ],
   "source": [
    "temp_str = \"Bring in the vaccine properly. What are you doing?\"\n",
    "\n",
    "sentiment_predict(temp_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "537bd2f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.97% 확률로 긍정 리뷰입니다.\n"
     ]
    }
   ],
   "source": [
    "temp_str = \"You will come after a good night's sleep\"\n",
    "\n",
    "sentiment_predict(temp_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a162ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
